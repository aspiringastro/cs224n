{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a03b760f-0f20-4294-a217-8c1eb9da77ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/ajithj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa40c070-415b-4013-a6d0-5c0e4d7fe6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun            : dark, darkness\n",
      "noun            : iniquity, wickedness, darkness, dark\n",
      "noun            : darkness, dark, shadow\n",
      "noun            : night, nighttime, dark\n",
      "noun            : dark, darkness\n",
      "adj             : dark\n",
      "adj             : dark\n",
      "adj (s)         : dark\n",
      "adj (s)         : black, dark, sinister\n",
      "adj (s)         : dark\n",
      "adj (s)         : dark, dour, glowering, glum, moody, morose, saturnine, sour, sullen\n",
      "adj (s)         : benighted, dark\n",
      "adj (s)         : dark, obscure\n",
      "adj (s)         : blue, dark, dingy, disconsolate, dismal, gloomy, grim, sorry, drab, drear, dreary\n",
      "adj (s)         : colored, coloured, dark, dark-skinned, non-white\n",
      "adj (s)         : dark\n"
     ]
    }
   ],
   "source": [
    "# Synonmym Sets of \"dark\"\n",
    "\n",
    "poses = { 'n': 'noun', 'v': 'verb', 's':'adj (s)', 'a': 'adj', 'r': 'adv' }\n",
    "tokens = []\n",
    "for synset in wn.synsets(\"dark\"):\n",
    "    tokens.extend([l.name() for l in synset.lemmas()])\n",
    "    lemmas = \", \".join([l.name() for l in synset.lemmas()])\n",
    "    print(f\"{poses[synset.pos()]:<16s}: {lemmas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909f52f4-3883-4a70-9a00-d0d2e482382a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('procyonid.n.01'),\n",
       " Synset('carnivore.n.01'),\n",
       " Synset('placental.n.01'),\n",
       " Synset('mammal.n.01'),\n",
       " Synset('vertebrate.n.01'),\n",
       " Synset('chordate.n.01'),\n",
       " Synset('animal.n.01'),\n",
       " Synset('organism.n.01'),\n",
       " Synset('living_thing.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypernyms of \"panda\"\n",
    "from nltk.corpus import wordnet as wn\n",
    "panda = wn.synset(\"panda.n.01\")\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(panda.closure(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75d02a60-a013-4287-adc0-e0d04ed0fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajithj/mambaforge/envs/cs224n/lib/python3.10/site-packages/nltk/corpus/reader/wordnet.py:604: UserWarning: Discarded redundant search for Synset('vehicle.n.01') at depth 7\n",
      "  for synset in acyclic_breadth_first(self, rel, depth):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('submarine.n.01'),\n",
       " Synset('submersible.n.02'),\n",
       " Synset('warship.n.01'),\n",
       " Synset('military_vehicle.n.01'),\n",
       " Synset('ship.n.01'),\n",
       " Synset('vehicle.n.01'),\n",
       " Synset('vessel.n.02'),\n",
       " Synset('conveyance.n.03'),\n",
       " Synset('craft.n.02'),\n",
       " Synset('instrumentality.n.03'),\n",
       " Synset('artifact.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('object.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('entity.n.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "panda = wn.synset(\"nautilus.n.01\")\n",
    "hyper = lambda s: s.hypernyms()\n",
    "list(panda.closure(hyper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a755ead6-b5e0-4654-a718-28ea8eb04723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_label_encoded = label_encoder.fit_transform(tokens)\n",
    "label_encoded = integer_label_encoded.reshape(len(integer_label_encoded), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(label_encoded)\n",
    "\n",
    "print(onehot_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81342438-672d-4608-b9cd-1e7d93a8e6a3",
   "metadata": {},
   "source": [
    "### Problem with words as discrete symbols\n",
    "Example: in web search, if a user searches for “Seattle motel”, we would like to match\n",
    "documents containing “Seattle hotel”\n",
    "But:\n",
    "\n",
    "motel = [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
    "\n",
    "hotel = [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
    "\n",
    "These two vectors are orthogonal\n",
    "There is no natural notion of similarity for one-hot vectors!\n",
    "Solution:\n",
    "- Could try to rely on WordNet’s list of synonyms to get similarity?\n",
    "- But it is well-known to fail badly: incompleteness, etc.\n",
    "- Instead: learn to encode similarity in the vectors themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6710c90-fdb2-49d7-ba90-bf196919ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# “You shall know a word by the company it keeps” (J. R. Firth 1957: 11)\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83299113-c924-4b64-94b6-7d3fb93b59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the word2vec model\n",
    "\n",
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "451c9e4a-411c-44c1-b5de-9dbd2785b09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trees', 0.17272792756557465),\n",
       " ('eps', 0.16694682836532593),\n",
       " ('response', 0.11118265986442566),\n",
       " ('interface', 0.10940765589475632),\n",
       " ('system', 0.079634889960289),\n",
       " ('user', 0.04130302369594574),\n",
       " ('survey', 0.037712957710027695),\n",
       " ('graph', 0.00831594504415989),\n",
       " ('minors', -0.005896794609725475),\n",
       " ('computer', -0.07424270361661911)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "# Store just the words + their trained embeddings.\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")\n",
    "\n",
    "tokens = model.wv.most_similar('human', topn=10)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f74327d8-dfce-4432-bd28-4a3b1a05dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.032843146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.wv.similarity(tokens[-1][0], tokens[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b183cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "# Train a bigram detector.\n",
    "bigram_transformer = Phrases(common_texts)\n",
    "\n",
    "# Apply the trained MWE detector to a corpus, using the result to train a Word2vec model.\n",
    "model = Word2Vec(bigram_transformer[common_texts], min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "740995b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Compute cosine similarity between two keys.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "w1 : str\n",
      "    Input key.\n",
      "w2 : str\n",
      "    Input key.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "float\n",
      "    Cosine similarity between `w1` and `w2`.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/envs/cs224n/lib/python3.10/site-packages/gensim/models/keyedvectors.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "? model.wv.similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef7be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a4d28d06a1e671314069da8d29f5818a0dd6ba47ea0704778aa5e4e7e7f6a24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
